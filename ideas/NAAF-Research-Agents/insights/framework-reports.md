# External Framework Reports (Separate Reference)

This file summarizes **methodology** and **core insights** from external frameworks. It does **not** map or merge them into the Eight Layers model.

## 1) UNDP Artificial Intelligence Landscape Assessment (AILA)
**Purpose**
AILA is a whole-of-society readiness assessment that charts where a country stands on AI and what its next growth steps should be.

**Methodology highlights**
- Uses a whole-of-society approach to examine national AI readiness.
- Evaluates factors such as infrastructure, skills, data, innovation support, government strategic vision, technological capabilities, and mechanisms for accountability, inclusivity, safety, and transparency.
- Built around three pillars: AI Ecosystem, AI for Government, and AI Regulation and Ethics.

**Core insights you can reuse**
- Readiness is not only technical capacity; it also depends on governance and responsible use.
- Assessments should surface gaps and recommend concrete actions, not just rankings.

**Source**
https://www.undp.org/digital/aila

## 2) Oxford Insights Government AI Readiness Index (Framework 2025)
**Purpose**
A framework to assess how governments can harness AI to benefit the public.

**Methodology highlights**
- Measurement question: "To what extent can a government harness AI to benefit the public?"
- Six pillars: Policy Capacity, Governance, AI Infrastructure, Public Sector Adoption, Development and Diffusion, Resilience.
- Framework is updated to reflect changes in AI capabilities and governance since 2017.

**Core insights you can reuse**
- Government readiness is multidimensional, including policy, infrastructure, adoption, and social resilience.
- Public benefit is the central lens, not just technological advancement.

**Source**
https://oxfordinsights.com/ai-readiness/framework-2025/

## 3) CGD AI Evaluation Framework for the Development Sector
**Purpose**
A staged evaluation approach to decide which evaluation methods are appropriate as AI systems mature in real-world deployment.

**Methodology highlights**
- Four incremental evaluation levels: Model, Product, User, and Impact.
- Recommends aligning evaluation rigor to product maturity and avoiding premature impact studies.
- Focuses on AI-for-good and development outcomes with a strong emphasis on safety and real-world effectiveness.

**Core insights you can reuse**
- Evaluation should be staged and evidence should grow as deployment matures.
- Strong impact claims require rigorous counterfactual evaluation.

**Source**
https://www.cgdev.org/blog/ai-evaluation-framework-for-the-development-sector

## 4) UNESCO AI Readiness Assessment Methodology (RAM)
**Purpose**
A diagnostic tool for assessing national capacities to govern AI ethically, aligned to UNESCO's AI ethics recommendation.

**Methodology highlights**
- Implemented since 2023 in over 70 countries.
- Uses 195 qualitative and quantitative questions.
- Five dimensions: legal, social and cultural, scientific and educational, economic, technical and infrastructural.

**Core insights you can reuse**
- Ethical AI readiness needs cross-disciplinary evidence, not just technical metrics.
- A standardized questionnaire can surface uneven coverage and institutional gaps.

**Source**
https://www.unesco.org/ethics-ai/en/node/321
